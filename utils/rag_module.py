"""ELK-RAG ê³µí†µ ëª¨ë“ˆ (ì£¼ì‹ ê²€ìƒ‰ìš©) â€” ê³ ë„í™” ë²„ì „"""

import os
import json
import datetime
from dotenv import load_dotenv
from elasticsearch import Elasticsearch
from openai import OpenAI

load_dotenv()

INDEX_NAME = "stock_info"
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMS = 1536
CHAT_MODEL = "gpt-4o-mini"

# ì‹ ë¢°ë„ ë“±ê¸‰ ê¸°ì¤€ (RRF ì ìˆ˜)
# RRF ìµœëŒ€ ì´ë¡ ê°’: 1/61 + 1/61 â‰ˆ 0.0328 (ì–‘ìª½ 1ìœ„ ë™ì‹œ ë‹¬ì„±)
# ì‹¤ì œ ì ìˆ˜ ë²”ìœ„ë¥¼ ë°˜ì˜í•´ ë“±ê¸‰ ê¸°ì¤€ ì„¤ì •
CONFIDENCE_THRESHOLDS = {"ë†’ìŒ": 0.030, "ë³´í†µ": 0.016}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í´ë¼ì´ì–¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_es_client():
    """Elasticsearch í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    return Elasticsearch("http://localhost:9200", http_compress=True)


def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜. API í‚¤ ë¯¸ì„¤ì • ì‹œ ValueError ë°œìƒ."""
    api_key = os.getenv("AI_API_KEY")
    if not api_key:
        raise ValueError("AI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    return OpenAI(api_key=api_key)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìž„ë² ë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_embedding(openai_client, text: str) -> list:
    """í…ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
    response = openai_client.embeddings.create(input=text, model=EMBEDDING_MODEL)
    return response.data[0].embedding


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Semantic + Lexical â†’ RRF)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_hybrid(es, openai_client, query: str, k: int = 5) -> list:
    """
    Reciprocal Rank Fusion(RRF)ìœ¼ë¡œ ì‹œë§¨í‹± + ë ‰ì‹œì»¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²°í•©.

    ë°˜í™˜: [{"íšŒì‚¬ëª…": str, "score": float, "rank": int}, ...]
      - score: RRF ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ê´€ë ¨ì„± ë†’ìŒ, ì‹ ë¢°ë„ íŒë‹¨ì— ì‚¬ìš©)
      - rank : ìµœì¢… ìˆœìœ„ (1-based)
    """
    query_embedding = get_embedding(openai_client, query)

    # â”€â”€ ì‹œë§¨í‹± ê²€ìƒ‰ (KNN)
    sem_resp = es.search(
        index=INDEX_NAME,
        knn={
            "field": "embedding",
            "query_vector": query_embedding,
            "k": k,
            "num_candidates": k * 10,
        },
        source={"excludes": ["embedding", "combined_text"]},
        size=k,
    )

    # â”€â”€ ë ‰ì‹œì»¬ ê²€ìƒ‰ (multi_match, íšŒì‚¬ëª… ê°€ì¤‘ì¹˜ ë†’ìž„)
    lex_resp = es.search(
        index=INDEX_NAME,
        query={
            "bool": {
                "should": [
                    {
                        # íšŒì‚¬ëª…ì´ ì •í™•ížˆ ì¼ì¹˜í•˜ë©´ boost=10ìœ¼ë¡œ ì••ë„ì  ìš°ì„ ìˆœìœ„ ë¶€ì—¬
                        "term": {
                            "íšŒì‚¬ëª….keyword": {
                                "value": query,
                                "boost": 10,
                            }
                        }
                    },
                    {
                        # ë¶€ë¶„ ë§¤ì¹­ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ (ì—…ì¢…Â·ì£¼ìš”ì œí’ˆ í¬í•¨)
                        "multi_match": {
                            "query": query,
                            "fields": ["íšŒì‚¬ëª…^3", "ì—…ì¢…^2", "ì£¼ìš”ì œí’ˆ"],
                            "type": "best_fields",
                        }
                    },
                ],
                "minimum_should_match": 1,
            }
        },
        source={"excludes": ["embedding", "combined_text"]},
        size=k,
    )


    # â”€â”€ RRF ì ìˆ˜ ê³„ì‚° (RRF_K=60 ì€ Elasticsearch ê³µì‹ ê¶Œìž¥ê°’)
    RRF_K = 60
    rrf_scores: dict = {}
    name_map: dict = {}

    for rank, hit in enumerate(sem_resp["hits"]["hits"], start=1):
        doc_id = hit["_id"]
        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (RRF_K + rank)
        name_map[doc_id] = hit["_source"]["íšŒì‚¬ëª…"]

    for rank, hit in enumerate(lex_resp["hits"]["hits"], start=1):
        doc_id = hit["_id"]
        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1 / (RRF_K + rank)
        name_map[doc_id] = hit["_source"]["íšŒì‚¬ëª…"]

    sorted_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)[:k]

    return [
        {"íšŒì‚¬ëª…": name_map[doc_id], "score": round(score, 6), "rank": i + 1}
        for i, (doc_id, score) in enumerate(sorted_docs)
    ]


def get_confidence_label(score: float) -> tuple:
    """RRF ì ìˆ˜ â†’ (ì‹ ë¢°ë„ ë ˆì´ë¸”, ì´ëª¨ì§€ ìƒ‰ìƒ)"""
    if score >= CONFIDENCE_THRESHOLDS["ë†’ìŒ"]:
        return "ë†’ìŒ", "ðŸŸ¢"
    elif score >= CONFIDENCE_THRESHOLDS["ë³´í†µ"]:
        return "ë³´í†µ", "ðŸŸ¡"
    else:
        return "ë‚®ìŒ", "ðŸ”´"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒì„¸ ì •ë³´ ì¡°íšŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_stock_details(es, company_names: list) -> list:
    """íšŒì‚¬ëª… ëª©ë¡ìœ¼ë¡œ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ìž„ë² ë”©Â·combined_text ì œì™¸)"""
    if not company_names:
        return []
    result = es.search(
        index=INDEX_NAME,
        query={"terms": {"íšŒì‚¬ëª….keyword": company_names}},
        source={"excludes": ["embedding", "combined_text"]},
        size=len(company_names),
    )
    return [hit["_source"] for hit in result["hits"]["hits"]]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì£¼ê°€ ì§ˆë¬¸ ê°ì§€ & ë‚ ì§œ íŒŒì‹± (ë©€í‹°í„´ ë§¥ë½ í¬í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_price_query(openai_client, query: str, chat_history: list) -> dict:
    """
    ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•´ ì£¼ê°€ ì¡°íšŒ ì—¬ë¶€ì™€ ë‚ ì§œ ë²”ìœ„ë¥¼ ì¶”ì¶œí•œë‹¤.

    Parameters
    ----------
    chat_history : [{"role": "user"|"assistant", "content": str}, ...]

    Returns
    -------
    {"is_price_query": bool, "start_date": str|None, "end_date": str|None}
    """
    today = datetime.date.today().isoformat()
    system_prompt = (
        "ë‹¹ì‹ ì€ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ëŠ” ë„ìš°ë¯¸ìž…ë‹ˆë‹¤. "
        "ì´ì „ ëŒ€í™”ì™€ í˜„ìž¬ ì§ˆë¬¸ì„ ì¢…í•©í•˜ì—¬ ì•„ëž˜ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\n"
        "{\n"
        '  "is_price_query": true/false,\n'
        '  "start_date": "YYYY-MM-DD ë˜ëŠ” null",\n'
        '  "end_date": "YYYY-MM-DD ë˜ëŠ” null"\n'
        "}\n\n"
        "is_price_query: ì£¼ê°€, ì°¨íŠ¸, ì‹œì„¸, ê°€ê²© ì¶”ì´ ìš”ì²­ì´ë©´ true.\n"
        "start_date: ëª…ì‹œëœ ì‹œìž‘ì¼. ì—†ìœ¼ë©´ null (â†’ ìƒìž¥ì¼ ê¸°ì¤€).\n"
        f"end_date: ëª…ì‹œëœ ì¢…ë£Œì¼. ì—†ìœ¼ë©´ null (â†’ ì˜¤ëŠ˜ {today}).\n"
        "ì—°ë„ë§Œ ìžˆìœ¼ë©´ í•´ë‹¹ ì—°ë„ 1ì›” 1ì¼ / 12ì›” 31ì¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n"
        "ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê¸°ê°„ì´ í˜„ìž¬ ì§ˆë¬¸ì— ì•”ë¬µì ìœ¼ë¡œ ì ìš©ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
    )

    recent_history = chat_history[-6:] if len(chat_history) > 6 else chat_history
    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(recent_history)
    messages.append({"role": "user", "content": query})

    response = openai_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=messages,
        temperature=0,
    )
    raw = response.choices[0].message.content.strip()
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        return {"is_price_query": False, "start_date": None, "end_date": None}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RAG ë‹µë³€ (ë©€í‹°í„´ + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ì‹ ë¢°ë„)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def answer_question(
    es,
    openai_client,
    query: str,
    chat_history: list = None,
) -> tuple:
    """
    í•˜ì´ë¸Œë¦¬ë“œ RAG ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€.

    Parameters
    ----------
    es            : Elasticsearch í´ë¼ì´ì–¸íŠ¸
    openai_client : OpenAI í´ë¼ì´ì–¸íŠ¸
    query         : í˜„ìž¬ ì‚¬ìš©ìž ìž…ë ¥
    chat_history  : [{"role": ..., "content": ...}] ì´ì „ ëŒ€í™” (ê¸°ë³¸ê°’: [])

    Returns
    -------
    (answer: str, scored_docs: list[dict], price_info: dict)
      scored_docs ì˜ˆì‹œ: [{"íšŒì‚¬ëª…": "ì‚¼ì„±ì „ìž", "score": 0.0312, "rank": 1}, ...]
      price_info  ì˜ˆì‹œ: {"is_price_query": True, "start_date": "2023-01-01", "end_date": None}
    """
    if chat_history is None:
        chat_history = []

    # â‘  ì£¼ê°€ ì§ˆë¬¸ ì—¬ë¶€ (ëŒ€í™” ë§¥ë½ í¬í•¨)
    price_info = detect_price_query(openai_client, query, chat_history)

    # â‘¡ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ â†’ ì ìˆ˜ í¬í•¨ ê²°ê³¼
    scored_docs = search_hybrid(es, openai_client, query, k=5)

    if not scored_docs:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì£¼ì‹ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", [], price_info

    company_names = [d["íšŒì‚¬ëª…"] for d in scored_docs]
    detail_info = search_stock_details(es, company_names)

    # â‘¢ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    if price_info.get("is_price_query"):
        system_content = (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì£¼ì‹ íƒìƒ‰ ë¹„ì„œìž…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìžê°€ ì£¼ê°€(ì‹œì„¸) ì •ë³´ë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. "
            "ê²€ìƒ‰ëœ ì¢…ëª©ì˜ íšŒì‚¬ëª…, ì—…ì¢…, ì£¼ìš”ì œí’ˆì„ ê°„ëžµížˆ ì†Œê°œí•˜ê³ , "
            "ì£¼ê°€ ì°¨íŠ¸ëŠ” ë³„ë„ë¡œ í‘œì‹œë  ì˜ˆì •ìž„ì„ ì•ˆë‚´í•´ ì£¼ì„¸ìš”. "
            "ì‘ë‹µì€ 300ìž ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìž‘ì„±í•˜ì„¸ìš”."
        )
    else:
        system_content = (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì£¼ì‹ íƒìƒ‰ ë¹„ì„œìž…ë‹ˆë‹¤. "
            "ì œê³µëœ 'íšŒì‚¬ ìƒì„¸ ì •ë³´'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. "
            "ê²€ìƒ‰ëœ íšŒì‚¬ì˜ ì£¼ìš” ì œí’ˆì´ë‚˜ ì—…ì¢… íŠ¹ì§•ì„ ì—®ì–´ì„œ ìžì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. "
            "ì´ì „ ëŒ€í™” íë¦„ì„ ê³ ë ¤í•´ ìžì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ë‹µë³€í•˜ì„¸ìš”. "
            "ì‘ë‹µì€ 500ìž ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë‹µë³€í•˜ì„¸ìš”."
        )

    # â‘£ ë©€í‹°í„´: ì´ì „ ëŒ€í™” + í˜„ìž¬ ì»¨í…ìŠ¤íŠ¸ ê²°í•©
    context_str = ", ".join(company_names)
    user_prompt = (
        f"ê²€ìƒ‰ëœ ê´€ë ¨ íšŒì‚¬ë“¤: {context_str}\n\n"
        f"íšŒì‚¬ ìƒì„¸ ì •ë³´: {detail_info}\n\n"
        f"ì‚¬ìš©ìž ì§ˆë¬¸: {query}\n\n"
        f"ë‹µë³€:"
    )

    recent_history = chat_history[-6:] if len(chat_history) > 6 else chat_history
    messages = [{"role": "system", "content": system_content}]
    messages.extend(recent_history)
    messages.append({"role": "user", "content": user_prompt})

    response = openai_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=messages,
    )
    answer = response.choices[0].message.content
    return answer, scored_docs, price_info